{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlYwwlVNYTQJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3El9g_GXYayN"
   },
   "outputs": [],
   "source": [
    "def splitTrainTest(data,percent):\n",
    "    total=len(data)\n",
    "    trainTotal=int(total*percent*0.01)\n",
    "    testTotal=total-trainTotal\n",
    "    return (data[0:trainTotal],data[trainTotal:total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5q_LrpcRa4sm"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "  def __init__(self,nNodesCurrent, nNodesNext, activationF):\n",
    "    self.nodesNo=nNodesCurrent\n",
    "    self.activations = np.zeros([nNodesCurrent,1])\n",
    "    self.activationF=activationF\n",
    "    \n",
    "    if nNodesNext==0:\n",
    "      self.weights=None\n",
    "    else:\n",
    "      self.weights=np.random.normal(0, 0.001, size=(nNodesCurrent,nNodesNext))\n",
    "#       self.weights=np.random.rand(nNodesCurrent,nNodesNext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foJcY9UbkqRp"
   },
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "  def __init__(self, totalLayers, noNodesList, activationFunctions):\n",
    "    self.totalLayers=totalLayers\n",
    "    self.noNodesList=noNodesList\n",
    "    self.layers = []\n",
    "    for i in range(totalLayers):\n",
    "      currentLayerNodes=noNodesList[i]\n",
    "      if i!=totalLayers-1:\n",
    "        nextLayerNodes=noNodesList[i+1]\n",
    "        ith_Layer=Layer(currentLayerNodes,nextLayerNodes,activationFunctions[i])\n",
    "      else:\n",
    "        ith_Layer=Layer(currentLayerNodes,0,activationFunctions[i])\n",
    "      self.layers.append(ith_Layer)#append output layer as none\n",
    "\n",
    "  def trainNetwork(self, data, batchSize, epochs, learningRate):\n",
    "    self.epochs=epochs\n",
    "    self.learningRate=learningRate\n",
    "    self.batchSize=batchSize;\n",
    "    outputLabels=data[:,0]#output labels one column\n",
    "    for x in range(epochs):\n",
    "      i=0\n",
    "      while i<len(data):\n",
    "        self.forwardPropo(data[i:i+batchSize,1:])#input\n",
    "        self.calculateError(outputLabels[i:i+batchSize])#output\n",
    "        print(\"==============================\")\n",
    "        i+=batchSize\n",
    "          \n",
    "  def forwardPropo(self, inputs):\n",
    "    self.layers[0].activations =inputs\n",
    "    for i in range(self.totalLayers-1):\n",
    "      # print(i+1)\n",
    "      # print(self.layers[i].weights.shape,i)\n",
    "      temp=np.matmul(self.layers[i].activations,self.layers[i].weights)  \n",
    "      print(\"==============================\")\n",
    "      if self.layers[i+1].activationF == \"sigmoid\":\n",
    "        self.layers[i+1].activations = self.sigmoid(temp)\n",
    "      elif self.layers[i+1].activationF == \"softmax\":\n",
    "        self.layers[i+1].activations = self.softmax(temp)\n",
    "      elif self.layers[i+1].activationF == \"relu\":\n",
    "        self.layers[i+1].activations = self.relu(temp)\n",
    "      elif self.layers[i+1].activationF == \"tanh\":\n",
    "        self.layers[i+1].activations = self.tanh(temp)\n",
    "      # print(self.layers[self.totalLayers-1].activations)\n",
    "        \n",
    "    def calculateError(self,labels):\n",
    "      print(labels)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "      return 1/(1+np.e**(-x))\n",
    "    \n",
    "    def relu(self, x):\n",
    "      x[x<0] = 0\n",
    "      return x\n",
    "\n",
    "    def softmax(self, x):\n",
    "      exp = np.exp(x)\n",
    "      if isinstance(x[0], np.ndarray):\n",
    "        return exp/np.sum(exp, axis=1, keepdims=True)\n",
    "      # else:\n",
    "    #     \t\treturn exp/np.sum(exp, keepdims=True)\n",
    "\n",
    "    def tanh(self, x):\n",
    "      return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQ5KUVammIaS"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Apparel/apparel-trainval.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ievzm6hptydg"
   },
   "outputs": [],
   "source": [
    "nn=NeuralNet(4,[784,16,16,10],[\"sigmoid\",\"sigmoid\",\"sigmoid\",\"sigmoid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1938
    },
    "colab_type": "code",
    "id": "W-_GNGBct1aP",
    "outputId": "0be1d7d6-ca47-4882-a0d8-2a7005477d07",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.trainNetwork(data,10000,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ud9EgMOW0yU6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ass5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
