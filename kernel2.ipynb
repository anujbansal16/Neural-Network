{
  "cells": [
    {
      "metadata": {
        "_uuid": "5b6fe18165db2e3add5bcb8f833fa86cdc3d6e94"
      },
      "cell_type": "markdown",
      "source": "# Assignment-5"
    },
    {
      "metadata": {
        "_uuid": "d32a6f32c3f360ebdf59a16e7757a34c9581c7b1"
      },
      "cell_type": "markdown",
      "source": "### Import necessary libraries"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DlYwwlVNYTQJ",
        "trusted": true,
        "_uuid": "d78c30fb1ae3fbe28508c51b0388e9a6e7ac1f54"
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import HTML\nimport base64",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3El9g_GXYayN",
        "trusted": true,
        "_uuid": "c902470f1c4c7ca9b8a9f330a312f7869c646e73"
      },
      "cell_type": "code",
      "source": "def splitTrainTest(data,percent):\n    total=len(data)\n    trainTotal=int(total*percent*0.01)\n    testTotal=total-trainTotal\n    return (data[0:trainTotal],data[trainTotal:total])",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d412f765569938aaf02b03aace0c70f774c95960"
      },
      "cell_type": "markdown",
      "source": "### Layer Class\nThis class's object represent the layers in neural network. It stores the number of neurons in each layers, activations, activation function associated with each layer and their weight vector (initialize on gaussian distribute with mean =0 and std deviation=1)."
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5q_LrpcRa4sm",
        "trusted": true,
        "_uuid": "296710bb41c7f337c77f17726e26c77c4c04e2c0"
      },
      "cell_type": "code",
      "source": "class Layer:\n    def __init__(self,nNodesCurrent, nNodesNext, activationF):\n        self.nodesNo=nNodesCurrent\n        self.activations = np.zeros([nNodesCurrent,1])\n        self.activationF=activationF\n        if nNodesNext==0:\n            self.weights=None\n        else:\n            self.weights=np.random.normal(0, 1, size=(nNodesCurrent,nNodesNext))",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "56465628011c10a40ed62d4b7dc9603b334d7664"
      },
      "cell_type": "markdown",
      "source": "### Neural Network Class\nClass of neural network to perform multiclass classification using the cross entropy as cost function and softmax as probabilty distribution activation function.\n\nThis class perform following tasks:\n* Initialized the number of layers in neural network and create **Layer Class** object.\n* Train the neural network on batches of inputs there by performing the forward and backward propogation using below helper methods.\n\n#### Methods:\n1. **Forward Propogation** : Perform the forward propogation, calculate and stores activations at each of the \nlayer.\n$$ z_1= w_1^TX $$\n$$ a_1= f _1(z_1) $$\n$$ z_2= w_2^Ta_1 $$\n$$ \\hat{y}= a_2= f_2(z_2) $$\n2. **Calculate Error** : Here we calculate the cross entropy error of our neural network on the updated activations. This updation in activation take place after the updation of weights in gradient decent algorithm in backpropogation.\n<br>\nFor multiclass classification we use the below cross entropy cost function:\n$$ J =  -\\sum\\limits_{i} y \\log \\; \\hat{y} $$\n3. **Backward Propogation** : Here, we differentiate the cost function to minimize it, and find the optimal values of parameters ie weights at each of the layer.\n$$\\frac{\\partial J}{\\partial w_2 } =  \\frac{\\partial J}{\\partial \\hat{y} }  * \\frac{\\partial \\hat{y}}{\\partial z_2 }  * \\frac{\\partial z_2}{\\partial w_2 }   $$\n<br>\nalso for cross entropy as a cost function and softmax as $f_2(z_2)$ , \n$$ \\delta_3  =  \\frac{\\partial J}{\\partial \\hat{y} }  * \\frac{\\partial \\hat{y}}{\\partial z_2 } = (y_p - y_a)  $$\n<br>\n$$ \\therefore   \\frac{\\partial J}{\\partial w_2 }= (\\hat{y} - y) * a_1$$\n<br><br>\nSimilarly to calculate parital derivative w.r.t weights of inner layers, we can use the chain rule\n$$   \\frac{\\partial J}{\\partial w_1 } = x^T *  \\delta_3 *  w_2 *  f^1 (z_1)      $$\n\n4. **Get Accuracy**: This function will return the accuracy of our neural network on multiclass classification.\n\n<hr>\n\n**Some important activations functions and their derivatives used in our network**\n**Softmax**\n<br>\n$$\\sigma (z)_j = \\frac{e^{z_j}}{\\sum^K_{k=1} e^{z_j}}$$\n**Sigmoid**\n<br>\n$$sigmoid(x) = \\frac{1}{1+\\epsilon ^ {-x}}$$\n$$\\frac{\\partial sigmoid(x)}{\\partial x} = sigmoid(x) * ( 1- sigmoid(x))$$\n\n**Relu**\n<br>\n$$relu(x) = \\max{(0,x)}$$\n<br>\n$$\\frac{\\partial relu(x)}{\\partial x} = 1 \\;\\;\\;\\; if x>0  \\\\ 0 \\;\\;\\; elsewhere$$\n\n**tanh**\n<br>\n$$tanh(x) = \\tanh{(x)}$$\n<br>\n$$\\frac{\\partial tanh(x)}{\\partial x} = 1 - \\tanh^2{(x)}$$"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "foJcY9UbkqRp",
        "trusted": true,
        "_uuid": "e17771a8b78f252040509525f72dd6c69605adb8"
      },
      "cell_type": "code",
      "source": "class NeuralNet:\n    def __init__(self, totalLayers, noNodesList, activationFunctions):\n        self.totalLayers=totalLayers\n        self.noNodesList=noNodesList\n        self.layers = []\n        for i in range(totalLayers):\n            currentLayerNodes=noNodesList[i]\n            if i!=totalLayers-1:\n                nextLayerNodes=noNodesList[i+1]\n                ith_Layer=Layer(currentLayerNodes,nextLayerNodes,activationFunctions[i])\n            else:\n                ith_Layer=Layer(currentLayerNodes,0,activationFunctions[i])\n            self.layers.append(ith_Layer)#append output layer as none\n\n    def trainNetwork(self, data,outputLabels, batchSize, epochs, learningRate,notforGraph=True):\n        self.learningRate=learningRate\n        self.batchSize=batchSize;\n        \n        #normalize data\n#         data=((data-data.min(axis=0))/(data.max(axis=0)-data.min(axis=0)))\n#         data=data/255\n        \n        for x in range(epochs):\n            i=0  \n            while i<len(data):\n                self.error=0\n                self.forwardPropo(data[i:i+batchSize])#input\n                self.calculateError(outputLabels[i:i+batchSize])#output\n                self.backwardPropo(outputLabels[i:i+batchSize])\n                i+=batchSize\n            self.error /= batchSize\n            if notforGraph:\n                print(\"Epoch \",x,\"->Error: \", self.error)\n        if notforGraph==False:\n            print(self.error)\n            return self.error\n        \n          \n    def forwardPropo(self, inputs):\n        self.layers[0].activations =inputs\n        for i in range(self.totalLayers-1):\n            temp=np.matmul(self.layers[i].activations,self.layers[i].weights)  \n            if self.layers[i+1].activationF == \"sigmoid\":\n                self.layers[i+1].activations = self.sigmoid(temp)\n            elif self.layers[i+1].activationF == \"softmax\":\n                self.layers[i+1].activations = self.softmax(temp)\n            elif self.layers[i+1].activationF == \"relu\":\n                self.layers[i+1].activations = self.relu(temp)\n            elif self.layers[i+1].activationF == \"tanh\":\n                self.layers[i+1].activations = self.tanh(temp)\n            else:\n                self.layers[i+1].activations = temp\n        \n    def calculateError(self,labels):\n        if len(labels[0]) != self.layers[self.totalLayers-1].nodesNo:\n            print (\"Error: Label is not of the same shape as output layer.\")\n            print(\"Label: \", len(labels), \" : \", len(labels[0]))\n            print(\"Out: \", len(self.layers[self.totalLayers-1].activations), \" : \", len(self.layers[self.totalLayers-1].activations[0]))\n            return\n        self.error += np.negative(np.sum(np.multiply(labels, np.log(self.layers[self.totalLayers-1].activations))))\n    \n    def backwardPropo(self, labels):\n        targets = labels\n        i = self.totalLayers-1\n        y = self.layers[i].activations\n        \n        delta=(y-targets)\n        deltaw = np.dot(self.layers[i-1].activations.T, delta)/self.batchSize\n        new_weights = self.layers[i-1].weights - self.learningRate * deltaw\n        for i in range(i-1, 0, -1):\n            if self.layers[i].activationF==\"sigmoid\":\n                prime= self.sigmoid_derivative(np.matmul(self.layers[i-1].activations,self.layers[i-1].weights))\n            elif self.layers[i].activationF==\"relu\":\n                prime= self.relu_derivative(np.matmul(self.layers[i-1].activations,self.layers[i-1].weights))\n            elif self.layers[i].activationF==\"tanh\":\n                prime= self.tanh_derivative(np.matmul(self.layers[i-1].activations,self.layers[i-1].weights))\n            \n            delta=np.multiply(prime,delta.dot(self.layers[i].weights.T))\n            deltaw = np.dot(self.layers[i-1].activations.T, delta)/self.batchSize\n\n            self.layers[i].weights = new_weights\n            new_weights = self.layers[i-1].weights - self.learningRate * deltaw\n        self.layers[0].weights = new_weights\n    \n    def predict(self,inputs):\n#         inputs=inputs/255\n        self.batchSize = len(inputs)\n        self.forwardPropo(inputs)\n        a = self.layers[self.totalLayers-1].activations\n        predictions=[]\n        actuals=[]\n        for i in range(len(a)):\n            al=a[i].tolist()\n            predictions.append(al.index(max(al)))\n#             actuals.append(labels[i])\n        \n        a = np.array(predictions)\n#         b = np.array(actuals)\n#         df = pd.DataFrame({\"predictions\" : a, \"actuals\" : b})\n        df = pd.DataFrame({\"predictions\" : a})\n#         df.to_csv(\"predictions.csv\", index=False)\n        return self.create_download_link(df)\n\n        \n    def getAccuracy(self, inputs, labels, forGraph=False):\n#         inputs=inputs/255\n        self.batchSize = len(inputs)\n        self.forwardPropo(inputs)\n        a = self.layers[self.totalLayers-1].activations\n#         print(len(a))\n        total=0\n        correct=0\n        for i in range(len(a)):\n            total += 1\n            al = a[i].tolist()\n            if labels[i][al.index(max(al))] == 1:\n                correct += 1\n#         print(correct)\n        accuracy=correct*100/total\n        print(\"Accuracy: \", accuracy)\n        if forGraph:\n            return accuracy\n    \n    def sigmoid(self, x):\n        return np.divide(1, np.add(1, np.exp(np.negative(x))))\n    \n    def sigmoid_derivative(self,x):\n        return (self.sigmoid(x)*(1-self.sigmoid(x)))\n    \n    def relu(self, x):\n        return (x/700) * (x > 0)\n    \n    def relu_derivative(self,X):\n        return 1. * (X > 0)\n    \n    def softmax(self, x):\n        exp = np.exp(x)\n        if isinstance(x[0], np.ndarray):\n            return exp/np.sum(exp, axis=1, keepdims=True)\n        else:\n            return exp/np.sum(exp, keepdims=True)\n\n    def tanh(self, x):\n        return np.tanh(x)\n    \n    def tanh_derivative(self,x):\n        return 1.0 - np.tanh(x) ** 2\n    \n    def create_download_link(self,df, title = \"Download CSV file\", filename = \"predictions.csv\"):  \n        csv = df.to_csv()\n        b64 = base64.b64encode(csv.encode())\n        payload = b64.decode()\n        html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n        html = html.format(payload=payload,title=title,filename=filename)\n        return HTML(html)",
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f382776340b5b2ceb8352f6cd8511ad0835d8a1e"
      },
      "cell_type": "code",
      "source": "def getOneHotLabels(data,k):\n    one_hot_labels = np.zeros((len(data), k))\n    for i in range(len(data)):  \n        one_hot_labels[i,data[i,0]] = 1\n    return one_hot_labels",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SQ5KUVammIaS",
        "trusted": true,
        "_uuid": "29bb65a597a19af437582c16d930790b7a792a83"
      },
      "cell_type": "code",
      "source": "data=pd.read_csv(\"../input/assignment5/apparel-trainval.csv\").values\n# testdata=pd.read_csv(\"../input/fashionmnist/fashion-mnist_test.csv\").values\ntestdata=pd.read_csv(\"../input/appareltesting/apparel-test.csv\").values",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c1c1d1ec4f2f78ad27a9de4a66a4a1d185177d29"
      },
      "cell_type": "markdown",
      "source": "### Question-1 Part-2"
    },
    {
      "metadata": {
        "_uuid": "c1bc2859e42d7b0ed0315189773705eca5611969"
      },
      "cell_type": "markdown",
      "source": "**Sigmoid**"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ievzm6hptydg",
        "trusted": true,
        "_uuid": "55c624c07d44df9d4ae46f7c997f640163305b64"
      },
      "cell_type": "code",
      "source": "train,test=splitTrainTest(data,80)\noneHotLabelsTrain=getOneHotLabels(train,10)\noneHotLabelsTest=getOneHotLabels(test,10)\ntrainInputs=train[:,1:]\ntestInputs=test[:,1:]\nprint(\"Neural network with sigmoid activation function in hidden layers\")\n\nnumberofLayers=4\nnoofneurons=[784,16,16,10]\nactivationFunctions=[None,\"sigmoid\",\"sigmoid\",\"softmax\"]\nbatchSize=64\nepochs=50\nlearningRat=0.6\ntrainInputs=trainInputs/255\ntestInputs=testInputs/255\n\n#NeuralNet(noLayers, noNeurons in each layer, activationFunctions)\nnn=NeuralNet(numberofLayers,noofneurons,activationFunctions)\nnn.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,epochs,learningRat)\nnn.getAccuracy( testInputs, oneHotLabelsTest)",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Neural network with sigmoid activation function in hidden layers\nEpoch  0 ->Error:  0.7653560727112056\nEpoch  1 ->Error:  0.6322987829578448\nEpoch  2 ->Error:  0.5834848192662432\nEpoch  3 ->Error:  0.5432173515868918\nEpoch  4 ->Error:  0.499665450954071\nEpoch  5 ->Error:  0.4462451950105618\nEpoch  6 ->Error:  0.4313582014199258\nEpoch  7 ->Error:  0.42238813931749397\nEpoch  8 ->Error:  0.41548275819946284\nEpoch  9 ->Error:  0.4046116391763186\nEpoch  10 ->Error:  0.3911782845210542\nEpoch  11 ->Error:  0.37566405356400523\nEpoch  12 ->Error:  0.363880922372683\nEpoch  13 ->Error:  0.35634752824963994\nEpoch  14 ->Error:  0.3481750479245461\nEpoch  15 ->Error:  0.33866664984813344\nEpoch  16 ->Error:  0.32911120407312877\nEpoch  17 ->Error:  0.3204789813573341\nEpoch  18 ->Error:  0.3138262379915813\nEpoch  19 ->Error:  0.30880376715429614\nEpoch  20 ->Error:  0.3048431970966675\nEpoch  21 ->Error:  0.3018142230818448\nEpoch  22 ->Error:  0.29966210596370185\nEpoch  23 ->Error:  0.29844604881116404\nEpoch  24 ->Error:  0.29856191185329994\nEpoch  25 ->Error:  0.29909796401228106\nEpoch  26 ->Error:  0.2993456497211713\nEpoch  27 ->Error:  0.2978724762117412\nEpoch  28 ->Error:  0.2949444884984752\nEpoch  29 ->Error:  0.2914823272176865\nEpoch  30 ->Error:  0.28828617354193786\nEpoch  31 ->Error:  0.28457810925230953\nEpoch  32 ->Error:  0.2824282066803147\nEpoch  33 ->Error:  0.27987247228791845\nEpoch  34 ->Error:  0.27703674853280924\nEpoch  35 ->Error:  0.2743066066595926\nEpoch  36 ->Error:  0.2706962778539292\nEpoch  37 ->Error:  0.2667599345600741\nEpoch  38 ->Error:  0.2628503928870219\nEpoch  39 ->Error:  0.25925039319542276\nEpoch  40 ->Error:  0.2559480916179522\nEpoch  41 ->Error:  0.2526104914413182\nEpoch  42 ->Error:  0.2494021102248585\nEpoch  43 ->Error:  0.24652140121302918\nEpoch  44 ->Error:  0.24347821459680774\nEpoch  45 ->Error:  0.2405044936641434\nEpoch  46 ->Error:  0.23785829291188137\nEpoch  47 ->Error:  0.23556302681532368\nEpoch  48 ->Error:  0.23348185492050524\nEpoch  49 ->Error:  0.23244700430992332\nAccuracy:  84.49166666666666\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "49acb05f48981d1aa92fd24dc9797019ad2adc9d"
      },
      "cell_type": "markdown",
      "source": "**ReLU**"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ievzm6hptydg",
        "trusted": true,
        "_uuid": "55c624c07d44df9d4ae46f7c997f640163305b64",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "train,test=splitTrainTest(data,80)\noneHotLabelsTrain=getOneHotLabels(train,10)\noneHotLabelsTest=getOneHotLabels(test,10)\ntrainInputs=train[:,1:]\ntestInputs=test[:,1:]\n\n# testUnseen=testdata#this is input as well\n\nprint(\"Neural network with reLU activation function in hidden layers\")\n\nnumberofLayers=4\nnoofneurons=[784,16,16,10]\nactivationFunctions=[None,\"relu\",\"relu\",\"softmax\"]\nbatchSize=64\nepochs=50\nlearningRat=0.6\ntrainInputs=trainInputs/255\ntestInputs=testInputs/255\n# testUnseen=testUnseen/255\n\n#NeuralNet(noLayers, noNeurons in each layer, activationFunctions)\nnn=NeuralNet(numberofLayers,noofneurons,activationFunctions)\n\nnn.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,epochs,learningRat)\n\nnn.getAccuracy( testInputs, oneHotLabelsTest)\n# nn.predict(testUnseen)\n",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Neural network with reLU activation function in hidden layers\nEpoch  0 ->Error:  0.48261267442601213\nEpoch  1 ->Error:  0.32973840008221966\nEpoch  2 ->Error:  0.292184736067002\nEpoch  3 ->Error:  0.27362624399509233\nEpoch  4 ->Error:  0.26864889007580034\nEpoch  5 ->Error:  0.2696503073593122\nEpoch  6 ->Error:  0.27344642167218836\nEpoch  7 ->Error:  0.2814378942228182\nEpoch  8 ->Error:  0.2626993220983243\nEpoch  9 ->Error:  0.25942208188853555\nEpoch  10 ->Error:  0.24643638089892367\nEpoch  11 ->Error:  0.2414481157012983\nEpoch  12 ->Error:  0.23208872750234547\nEpoch  13 ->Error:  0.23651015484987986\nEpoch  14 ->Error:  0.2303462499778317\nEpoch  15 ->Error:  0.23158521224552642\nEpoch  16 ->Error:  0.22980344526017188\nEpoch  17 ->Error:  0.22622479866004042\nEpoch  18 ->Error:  0.22087336988877088\nEpoch  19 ->Error:  0.21764570094816005\nEpoch  20 ->Error:  0.2071338903449631\nEpoch  21 ->Error:  0.20306002506573356\nEpoch  22 ->Error:  0.20457852028815332\nEpoch  23 ->Error:  0.2040165323019378\nEpoch  24 ->Error:  0.20176788296846965\nEpoch  25 ->Error:  0.19628137612225888\nEpoch  26 ->Error:  0.19629021920251347\nEpoch  27 ->Error:  0.19154860195010434\nEpoch  28 ->Error:  0.19868598107754465\nEpoch  29 ->Error:  0.19438418527013063\nEpoch  30 ->Error:  0.19223092981695494\nEpoch  31 ->Error:  0.19010019521326837\nEpoch  32 ->Error:  0.1955028304781033\nEpoch  33 ->Error:  0.19294726444840207\nEpoch  34 ->Error:  0.19243824189116387\nEpoch  35 ->Error:  0.19168521442254555\nEpoch  36 ->Error:  0.19373267620712128\nEpoch  37 ->Error:  0.19784308241457454\nEpoch  38 ->Error:  0.1981817358203662\nEpoch  39 ->Error:  0.18978207167545535\nEpoch  40 ->Error:  0.19094747649881239\nEpoch  41 ->Error:  0.19371821239956152\nEpoch  42 ->Error:  0.18316426026044974\nEpoch  43 ->Error:  0.17911021318029258\nEpoch  44 ->Error:  0.18261775571257777\nEpoch  45 ->Error:  0.18131114519983027\nEpoch  46 ->Error:  0.1831063662425311\nEpoch  47 ->Error:  0.18686613405775757\nEpoch  48 ->Error:  0.18355194235383152\nEpoch  49 ->Error:  0.1839798623994035\nAccuracy:  86.38333333333334\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "9ccdbe974cf8b9644a04fd700dced65302c64f1d"
      },
      "cell_type": "markdown",
      "source": "**Tanh**"
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ievzm6hptydg",
        "trusted": true,
        "_uuid": "55c624c07d44df9d4ae46f7c997f640163305b64",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "train,test=splitTrainTest(data,80)\noneHotLabelsTrain=getOneHotLabels(train,10)\noneHotLabelsTest=getOneHotLabels(test,10)\ntrainInputs=train[:,1:]\ntestInputs=test[:,1:]\nprint(\"Neural network with tanh activation function in hidden layers\")\n\nnumberofLayers=4\nnoofneurons=[784,16,16,10]\nactivationFunctions=[None,\"tanh\",\"tanh\",\"softmax\"]\nbatchSize=64\nepochs=50\nlearningRat=0.3\ntrainInputs=trainInputs/255\ntestInputs=testInputs/255\n\n\n#NeuralNet(noLayers, noNeurons in each layer, activationFunctions)\nnn=NeuralNet(numberofLayers,noofneurons,activationFunctions)\nnn.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,epochs,learningRat)\nnn.getAccuracy( testInputs, oneHotLabelsTest)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "009118e7f3e0922109fb5daebe69e05e0b882e7b"
      },
      "cell_type": "code",
      "source": "def errorPlot():\n    data=pd.read_csv(\"../input/assignment5/apparel-trainval.csv\").values\n    sigmoidError=[]\n    reluError=[]\n    tanhError=[]\n    xlist=[i for i in range(1,56)]\n    train,test=splitTrainTest(data,80)\n    oneHotLabelsTrain=getOneHotLabels(train,10)\n    oneHotLabelsTest=getOneHotLabels(test,10)\n    trainInputs=train[:,1:]\n    testInputs=test[:,1:]\n    \n    trainInputs=trainInputs/255\n    testInputs=testInputs/255\n    \n\n    numberofLayers=4\n    noofneurons=[784,16,16,10]\n    activationFunctionsRelu=[None,\"relu\",\"relu\",\"softmax\"]\n    activationFunctionsSigmoid=[None,\"sigmoid\",\"sigmoid\",\"softmax\"]\n    activationFunctionsTanh=[None,\"tanh\",\"tanh\",\"softmax\"]\n    batchSize=64\n    \n    for i in xlist:\n        print(i)\n        nnSigmoid=NeuralNet(numberofLayers,noofneurons,activationFunctionsSigmoid)\n        nnRelu=NeuralNet(numberofLayers,noofneurons,activationFunctionsRelu)\n        nnTanh=NeuralNet(numberofLayers,noofneurons,activationFunctionsTanh)\n        \n        nnSigmoid.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,i,0.1,False)\n        nnRelu.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,i,0.1,False)\n        nnTanh.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,i,0.1,False)\n        \n        sigmoidError.append(nnSigmoid.getAccuracy(testInputs, oneHotLabelsTest,True))\n        reluError.append(nnRelu.getAccuracy(testInputs, oneHotLabelsTest,True))\n        tanhError.append(nnTanh.getAccuracy(testInputs, oneHotLabelsTest,True))\n        \n    plt.title(\"Errors vs epocs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.grid(True)\n#     print(xlist,reluError,sigmoidError,tanhError)\n    plt.plot(xlist,reluError ,color=\"green\", linewidth=2.5,label=\"ReLU\")\n    plt.plot(xlist,tanhError,color=\"orange\", linewidth=2.5,label=\"Tanh\")\n    plt.plot(xlist, sigmoidError,color=\"m\", linewidth=2.5,label=\"Sigmoid\")\n\n    plt.legend(loc=3)\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "193ce135b2c898d19489b23b29fc1fdc23aee1ba",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "errorPlot()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4676627fd19e7fa68692c1d06a847dd00422ae08"
      },
      "cell_type": "code",
      "source": "def layersPlot():\n    data=pd.read_csv(\"../input/assignment5/apparel-trainval.csv\").values\n    sigmoidError=[]\n    reluError=[]\n    tanhError=[]\n    xlist=[i for i in range(0,6)]\n    train,test=splitTrainTest(data,80)#train on 80% data\n    oneHotLabelsTrain=getOneHotLabels(train,10)#10 is vector size\n    oneHotLabelsTest=getOneHotLabels(test,10)\n    trainInputs=train[:,1:]\n    testInputs=test[:,1:]\n    \n    trainInputs=trainInputs/255\n    testInputs=testInputs/255\n    epochs=50\n    batchSize=64\n    \n    for i in xlist:\n        print(i)\n        numberofLayers=2+i\n        \n        noofneurons=[784]+[16]*i+[10]\n        activationFunctionsRelu=[None]+[\"relu\"]*i+[\"softmax\"]\n        activationFunctionsSigmoid=[None]+[\"sigmoid\"]*i+[\"softmax\"]\n        activationFunctionsTanh=[None]+[\"tanh\"]*i+[\"softmax\"]\n#         print(noofneurons,activationFunctionsRelu,numberofLayers)\n        nnSigmoid=NeuralNet(numberofLayers,noofneurons,activationFunctionsSigmoid)\n        nnRelu=NeuralNet(numberofLayers,noofneurons,activationFunctionsRelu)\n        nnTanh=NeuralNet(numberofLayers,noofneurons,activationFunctionsTanh)\n        \n        sigmoidError.append(nnSigmoid.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,epochs,0.6,False))\n        reluError.append(nnRelu.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,epochs,0.6,False))\n        tanhError.append(nnTanh.trainNetwork(trainInputs,oneHotLabelsTrain,batchSize,epochs,0.3,False))\n        \n#         sigmoidError.append(nnSigmoid.getAccuracy(testInputs, oneHotLabelsTest,True))\n#         reluError.append(nnRelu.getAccuracy(testInputs, oneHotLabelsTest,True))\n#         tanhError.append(nnTanh.getAccuracy(testInputs, oneHotLabelsTest,True))\n        \n    plt.title(\"Loss vs Number of layers\")\n    plt.xlabel(\"Hidden Layers (each with 16 neurons)\")\n    plt.ylabel(\"Loss (Cross Entropy)\")\n    plt.grid(True)\n#     print(xlist,reluError,sigmoidError,tanhError)\n    plt.plot(xlist,reluError ,color=\"green\", linewidth=2.5,label=\"ReLU\")\n    plt.plot(xlist,tanhError,color=\"orange\", linewidth=2.5,label=\"Tanh\")\n    plt.plot(xlist, sigmoidError,color=\"m\", linewidth=2.5,label=\"Sigmoid\")\n\n    plt.legend(loc=0)\n    plt.show()",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8df610b7c589bba37b6f05013e052a7a1df65830",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "layersPlot()",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0\n0.5348684872705193\n0.5628134244739061\n0.4345390376868731\n1\n0.21450192349389996\n0.18364702417222656\n0.3037814465497284\n2\n0.28905382970074733\n0.20467435564651204\n0.2830050305891012\n3\n0.2791354516734865\n2.3025850929940455\n0.28329594421342547\n4\n0.33478208445313673\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:137: RuntimeWarning: overflow encountered in exp\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:60: RuntimeWarning: divide by zero encountered in log\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in multiply\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:131: RuntimeWarning: invalid value encountered in greater\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:134: RuntimeWarning: invalid value encountered in greater\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "nan\n0.5287228970072051\n5\n0.2574763538053355\nnan\n0.5555518429107476\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f6f3b0084f424b1af570797daf2b42f10de58b6"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Ass5.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}